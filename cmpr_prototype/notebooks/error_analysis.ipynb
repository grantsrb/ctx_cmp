{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa9a0f8-95f1-4db3-a518-1a861e076e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import collections\n",
    "sys.path.insert(1, \"../\")\n",
    "import ml_utils.save_io as io\n",
    "import ml_utils.utils as utils\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from models import SentenceAutoEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import datas\n",
    "\n",
    "#import matplotlib\n",
    "#font = {'family' : 'normal',\n",
    "#        'weight' : 'bold',\n",
    "#        'size'   : 40}\n",
    "#matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74522c48-b7c5-4263-a282-0b2ebe3398be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /data2/pdp/grantsrb/sa_saves/bloom560proj\n",
      "1 /data2/pdp/grantsrb/sa_saves/trsearch_gpt2\n",
      "2 /data2/pdp/grantsrb/sa_saves/bloom560_softouts\n",
      "3 /data2/pdp/grantsrb/sa_saves/cmplayer_gpt2\n",
      "4 /data2/pdp/grantsrb/sa_saves/test\n",
      "5 /data2/pdp/grantsrb/sa_saves/debug\n",
      "6 /data2/pdp/grantsrb/sa_saves/gptj\n",
      "7 /data2/pdp/grantsrb/sa_saves/bloom560_cmplen\n"
     ]
    }
   ],
   "source": [
    "root_paths = [\n",
    "    \"/data2/pdp/grantsrb/sa_saves/\",\n",
    "]\n",
    "exp_folders = []\n",
    "for root_path in root_paths:\n",
    "    for i,exp_folder in enumerate(os.listdir(root_path)):\n",
    "        exp_folders.append(os.path.join(root_path, exp_folder))\n",
    "        print(i,exp_folders[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "226bc0f4-3b93-499a-8daf-64318b6a20d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [ 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d12bc5cf-1b8e-4835-97b3-6033b1b8bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /data2/pdp/grantsrb/sa_saves/bloom560proj/bloom560proj_0_seq_len20_cmp_len10_sep_cmprTrue\n",
      "1 /data2/pdp/grantsrb/sa_saves/bloom560proj/bloom560proj_1_ddpTrue_seq_len20_cmp_len10_sep_cmprTrue\n",
      "2 /data2/pdp/grantsrb/sa_saves/bloom560proj/bloom560proj_2_seq_len20_cmp_len10_sep_cmprFalse\n"
     ]
    }
   ],
   "source": [
    "model_folders = []\n",
    "for idx in idxs:\n",
    "    exp_folder = exp_folders[idx]\n",
    "    new_folders = io.get_model_folders(exp_folder, incl_full_path=True)\n",
    "    model_folders = model_folders + new_folders\n",
    "for i,folder in enumerate(model_folders):\n",
    "    print(i,folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5279a723-6636-475e-8d67-ea8278ab7144",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "model_folder = model_folders[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b3fe3f1-7c6e-402e-b985-ed3ab49a007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpt = io.load_checkpoint(model_folder)\n",
    "hyps = checkpt[\"hyps\"]\n",
    "hyps[\"val_batch_size\"] = 75\n",
    "\n",
    "model = SentenceAutoEncoder(**hyps)\n",
    "model.load_state_dict(checkpt[\"state_dict\"])\n",
    "model = model.eval()\n",
    "if not hyps[\"model_parallel\"]: model = model.to(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f844f-20ae-4d51-994c-002c80ccd61f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b220e6d5-3d4c-4739-8e94-987e05611dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from /data2/pdp/grantsrb/datasplits/openwebtext1m/train\n",
      "Loading data from /data2/pdp/grantsrb/datasplits/openwebtext1m/val\n"
     ]
    }
   ],
   "source": [
    "# Make Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(hyps[\"model_string\"])\n",
    "tokenizer.truncation_side = \"right\"\n",
    "\n",
    "if tokenizer.pad_token is None:                                     \n",
    "    print(\"No Pad Token\")                                           \n",
    "    print(\"EOS:\", tokenizer.eos_token)                              \n",
    "    print(\"BOS:\", tokenizer.bos_token)                              \n",
    "    print(\"CLS:\", tokenizer.cls_token)                              \n",
    "    tokenizer.add_special_tokens(                                   \n",
    "        {\"pad_token\": hyps.get(\"pad_token\", tokenizer.eos_token)}   \n",
    "    )                                                               \n",
    "    print(\"PAD:\", tokenizer.pad_token)                              \n",
    "    if tokenizer.pad_token != tokenizer.eos_token:                  \n",
    "        print(\"PAD {} different from EOS {}\".format(                \n",
    "            tokenizer.pad_token, tokenizer.eos_token                \n",
    "        ))                                                          \n",
    "        # Adjust Model Embeddings for new token types               \n",
    "        model.add_embeddings(1)\n",
    "\n",
    "dataset, valset, dataloader, valloader = datas.get_loaders(         \n",
    "    hyps,                                                           \n",
    "    tokenizer,                                                      \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb11d54c-9be4-4d42-ae45-f9629e60cad5",
   "metadata": {},
   "source": [
    "## Examine Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fd6d8c-554c-4c68-b33e-03093546c1f9",
   "metadata": {},
   "source": [
    "### No Teacher Forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf64a917-5d20-434f-8ba7-4df10b91931a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [33:09,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "top_n = 5\n",
    "max_loops = 1000\n",
    "tforce = False\n",
    "model.rmb_task = False\n",
    "lossfxn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "loss_avgs = collections.defaultdict(lambda: [0,0])\n",
    "top1_tps = collections.defaultdict(lambda:  [0,0])\n",
    "top1_fps = collections.defaultdict(lambda:  [0,0])\n",
    "topn_tps = collections.defaultdict(lambda:  [0,0])\n",
    "avg_loss = 0\n",
    "avg_acc = 0\n",
    "avg_fps = 0\n",
    "avg_topn = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in tqdm(enumerate(valloader)):\n",
    "        if not hyps[\"model_parallel\"]:\n",
    "            data = {k: v.to(model.get_device()) for k,v in data.items()}\n",
    "        preds = model(data, tforce=tforce)\n",
    "        preds = preds.reshape(-1,preds.shape[-1])\n",
    "        idx = data[\"output_attn_mask\"].reshape(-1).bool()\n",
    "        preds = preds[idx]\n",
    "        targs = data[\"output_ids\"].reshape(-1)[idx]\n",
    "        losses = lossfxn(preds, targs)\n",
    "        avg_loss += losses.mean().item()\n",
    "        \n",
    "        top1 = preds.argmax(-1)\n",
    "        avg_acc += (top1==targs).float().mean().item()\n",
    "        \n",
    "        args = torch.topk(preds, top_n, largest=True, sorted=False, dim=-1).indices\n",
    "        avg_topn += (args==targs[:,None]).float().sum(-1).mean().item()\n",
    "        for id_ in set(targs.data.cpu().tolist()):\n",
    "            idx = targs==id_\n",
    "            s = idx.float().sum().item()\n",
    "            loss_avgs[id_][0] += losses[idx].sum().item()\n",
    "            top1_tps[id_][0] += (top1[idx]==targs[idx]).float().sum().item()\n",
    "            topn_tps[id_][0] += (args[idx]==targs[idx][:,None]).float().sum().item()\n",
    "            \n",
    "            loss_avgs[id_][1] += s\n",
    "            top1_tps[id_][1] += s\n",
    "            topn_tps[id_][1] += s\n",
    "            \n",
    "        for id_ in set(top1.data.cpu().tolist()):\n",
    "            idx = top1==id_\n",
    "            top1_fps[id_][0] += (top1[idx]!=targs[idx]).float().sum().item()\n",
    "            top1_fps[id_][1] += idx.float().sum().item()\n",
    "            \n",
    "        if i>max_loops: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34a7ca46-63de-4396-9d44-06753c347ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Loss: 10.7847\n",
      "Avg Top 1: 0.02904\n",
      "Avg Top 5: 0.07255\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg Loss:\", round(avg_loss/(i+1), 5))\n",
    "print(\"Avg Top 1:\", round(avg_acc/(i+1), 5))\n",
    "print(\"Avg Top {}:\".format(top_n), round(avg_topn/(i+1), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b22f84-ca5f-4179-821d-9dd87d22ed47",
   "metadata": {},
   "source": [
    "### Loss Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6e5286e-fe33-42d8-8421-7d507c988398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>loss</th>\n",
       "      <th>n_occurs</th>\n",
       "      <th>true_pos</th>\n",
       "      <th>top_k</th>\n",
       "      <th>false_pos</th>\n",
       "      <th>n_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notice</td>\n",
       "      <td>9.627829</td>\n",
       "      <td>358.0</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>0.204188</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>board</td>\n",
       "      <td>11.151226</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!</td>\n",
       "      <td>8.644848</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.006784</td>\n",
       "      <td>0.069199</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>775.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.\\n\\n</td>\n",
       "      <td>8.135287</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>0.019353</td>\n",
       "      <td>0.116471</td>\n",
       "      <td>0.959898</td>\n",
       "      <td>8204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"</td>\n",
       "      <td>9.981285</td>\n",
       "      <td>2323.0</td>\n",
       "      <td>0.084374</td>\n",
       "      <td>0.125700</td>\n",
       "      <td>0.943402</td>\n",
       "      <td>3463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42555</th>\n",
       "      <td>nag</td>\n",
       "      <td>27.095577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42556</th>\n",
       "      <td>Percy</td>\n",
       "      <td>13.574580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42557</th>\n",
       "      <td>=\"1</td>\n",
       "      <td>22.581146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42558</th>\n",
       "      <td>osur</td>\n",
       "      <td>16.072174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42559</th>\n",
       "      <td>bj</td>\n",
       "      <td>14.060807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42560 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word       loss  n_occurs  true_pos     top_k  false_pos  n_preds\n",
       "0       notice   9.627829     358.0  0.424581  0.424581   0.204188    191.0\n",
       "1        board  11.151226     153.0  0.006536  0.006536   0.987013     77.0\n",
       "2            !   8.644848     737.0  0.006784  0.069199   0.993548    775.0\n",
       "3        .\\n\\n   8.135287   17000.0  0.019353  0.116471   0.959898   8204.0\n",
       "4            \"   9.981285    2323.0  0.084374  0.125700   0.943402   3463.0\n",
       "...        ...        ...       ...       ...       ...        ...      ...\n",
       "42555      nag  27.095577       1.0  0.000000  0.000000   0.000000      0.0\n",
       "42556    Percy  13.574580       1.0  0.000000  0.000000   0.000000      0.0\n",
       "42557      =\"1  22.581146       1.0  0.000000  0.000000   0.000000      0.0\n",
       "42558     osur  16.072174       1.0  0.000000  0.000000   1.000000      2.0\n",
       "42559       bj  14.060807       1.0  0.000000  0.000000   0.000000      0.0\n",
       "\n",
       "[42560 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = {\n",
    "    \"word\":      [],\n",
    "    \"loss\":      [],\n",
    "    \"n_occurs\":  [],\n",
    "    \"true_pos\":  [],\n",
    "    \"top_k\":     [],\n",
    "    \"false_pos\": [],\n",
    "    \"n_preds\":   [],\n",
    "}\n",
    "sort_list = []\n",
    "tot_sum = 0\n",
    "for k in loss_avgs.keys():\n",
    "    name = tokenizer.decode(k)\n",
    "    df[\"word\"].append(name)\n",
    "    df[\"loss\"].append(loss_avgs[k][0]/loss_avgs[k][1])\n",
    "    df[\"n_occurs\"].append(loss_avgs[k][1])\n",
    "    df[\"true_pos\"].append(top1_tps[k][0]/top1_tps[k][1])\n",
    "    df[\"top_k\"].append(topn_tps[k][0]/topn_tps[k][1])\n",
    "    try:\n",
    "        df[\"false_pos\"].append(top1_fps[k][0]/top1_fps[k][1])\n",
    "        df[\"n_preds\"].append(top1_fps[k][1])\n",
    "    except:\n",
    "        df[\"false_pos\"].append(0)\n",
    "        df[\"n_preds\"].append(0)\n",
    "    tot_sum += loss_avgs[k][1]\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5090b5eb-5da2-4ee7-92f4-b5fb3318cb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fa0d9ad-3ea9-4a43-8066-e2c4d319457e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>loss</th>\n",
       "      <th>n_occurs</th>\n",
       "      <th>true_pos</th>\n",
       "      <th>top_k</th>\n",
       "      <th>false_pos</th>\n",
       "      <th>n_preds</th>\n",
       "      <th>loss_p</th>\n",
       "      <th>true_p</th>\n",
       "      <th>topk_p</th>\n",
       "      <th>false_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notice</td>\n",
       "      <td>9.627829</td>\n",
       "      <td>358.0</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>0.204188</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>1.011311e-04</td>\n",
       "      <td>1.011311e-04</td>\n",
       "      <td>0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>board</td>\n",
       "      <td>11.151226</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>6.653360e-07</td>\n",
       "      <td>6.653360e-07</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!</td>\n",
       "      <td>8.644848</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.006784</td>\n",
       "      <td>0.069199</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>775.0</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>3.326680e-06</td>\n",
       "      <td>3.393214e-05</td>\n",
       "      <td>0.000516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.\\n\\n</td>\n",
       "      <td>8.135287</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>0.019353</td>\n",
       "      <td>0.116471</td>\n",
       "      <td>0.959898</td>\n",
       "      <td>8204.0</td>\n",
       "      <td>0.092016</td>\n",
       "      <td>2.188955e-04</td>\n",
       "      <td>1.317365e-03</td>\n",
       "      <td>0.005281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"</td>\n",
       "      <td>9.981285</td>\n",
       "      <td>2323.0</td>\n",
       "      <td>0.084374</td>\n",
       "      <td>0.125700</td>\n",
       "      <td>0.943402</td>\n",
       "      <td>3463.0</td>\n",
       "      <td>0.015427</td>\n",
       "      <td>1.304059e-04</td>\n",
       "      <td>1.942781e-04</td>\n",
       "      <td>0.002191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42555</th>\n",
       "      <td>nag</td>\n",
       "      <td>27.095577</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42556</th>\n",
       "      <td>Percy</td>\n",
       "      <td>13.574580</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42557</th>\n",
       "      <td>=\"1</td>\n",
       "      <td>22.581146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42558</th>\n",
       "      <td>osur</td>\n",
       "      <td>16.072174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42559</th>\n",
       "      <td>bj</td>\n",
       "      <td>14.060807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42560 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word       loss  n_occurs  true_pos     top_k  false_pos  n_preds    loss_p        true_p        topk_p   false_p\n",
       "0       notice   9.627829     358.0  0.424581  0.424581   0.204188    191.0  0.002293  1.011311e-04  1.011311e-04  0.000026\n",
       "1        board  11.151226     153.0  0.006536  0.006536   0.987013     77.0  0.001135  6.653360e-07  6.653360e-07  0.000051\n",
       "2            !   8.644848     737.0  0.006784  0.069199   0.993548    775.0  0.004239  3.326680e-06  3.393214e-05  0.000516\n",
       "3        .\\n\\n   8.135287   17000.0  0.019353  0.116471   0.959898   8204.0  0.092016  2.188955e-04  1.317365e-03  0.005281\n",
       "4            \"   9.981285    2323.0  0.084374  0.125700   0.943402   3463.0  0.015427  1.304059e-04  1.942781e-04  0.002191\n",
       "...        ...        ...       ...       ...       ...        ...      ...       ...           ...           ...       ...\n",
       "42555      nag  27.095577       1.0  0.000000  0.000000   0.000000      0.0  0.000018  0.000000e+00  0.000000e+00  0.000000\n",
       "42556    Percy  13.574580       1.0  0.000000  0.000000   0.000000      0.0  0.000009  0.000000e+00  0.000000e+00  0.000000\n",
       "42557      =\"1  22.581146       1.0  0.000000  0.000000   0.000000      0.0  0.000015  0.000000e+00  0.000000e+00  0.000000\n",
       "42558     osur  16.072174       1.0  0.000000  0.000000   1.000000      2.0  0.000011  0.000000e+00  0.000000e+00  0.000001\n",
       "42559       bj  14.060807       1.0  0.000000  0.000000   0.000000      0.0  0.000009  0.000000e+00  0.000000e+00  0.000000\n",
       "\n",
       "[42560 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_sum = np.sum(df[\"n_occurs\"])\n",
    "df[\"loss_p\"] = df[\"loss\"]*df[\"n_occurs\"]/tot_sum\n",
    "df[\"true_p\"] = df[\"true_pos\"]*df[\"n_occurs\"]/tot_sum\n",
    "df[\"topk_p\"] = df[\"top_k\"]*df[\"n_occurs\"]/tot_sum\n",
    "df[\"false_p\"] = df[\"false_pos\"]*df[\"n_preds\"]/np.sum(df[\"n_preds\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb9420d6-c7cb-4abf-a460-8b542c175ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"p\"] = df[\"n_occurs\"]/tot_sum\n",
    "pred_sum = np.sum(df[\"n_preds\"])\n",
    "df[\"pred_p\"] = df[\"n_preds\"]/pred_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92650522-1486-4643-9b68-1a0098837d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>loss</th>\n",
       "      <th>n_occurs</th>\n",
       "      <th>true_pos</th>\n",
       "      <th>top_k</th>\n",
       "      <th>false_pos</th>\n",
       "      <th>n_preds</th>\n",
       "      <th>loss_p</th>\n",
       "      <th>true_p</th>\n",
       "      <th>topk_p</th>\n",
       "      <th>false_p</th>\n",
       "      <th>p</th>\n",
       "      <th>pred_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>See</td>\n",
       "      <td>3.188092</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.698171</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>0.154982</td>\n",
       "      <td>271.0</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>2.816401e-05</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4611</th>\n",
       "      <td>day</td>\n",
       "      <td>4.179189</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.731034</td>\n",
       "      <td>0.737931</td>\n",
       "      <td>0.595420</td>\n",
       "      <td>262.0</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.046092e-04</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8708</th>\n",
       "      <td>delivered</td>\n",
       "      <td>4.856407</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.638418</td>\n",
       "      <td>0.638418</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>3.352858e-06</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854</th>\n",
       "      <td>occasional</td>\n",
       "      <td>5.505368</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.597015</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.609372e-05</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12336</th>\n",
       "      <td>sustainable</td>\n",
       "      <td>6.594767</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>5.364573e-06</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19670</th>\n",
       "      <td>....</td>\n",
       "      <td>4.938991</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>1.274086e-05</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>letters</td>\n",
       "      <td>7.628775</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>3.352858e-06</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Show</td>\n",
       "      <td>4.990631</td>\n",
       "      <td>275.0</td>\n",
       "      <td>0.523636</td>\n",
       "      <td>0.523636</td>\n",
       "      <td>0.521595</td>\n",
       "      <td>301.0</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>1.052797e-04</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>promot</td>\n",
       "      <td>6.378230</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.521127</td>\n",
       "      <td>0.521127</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>6.705716e-06</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>privacy</td>\n",
       "      <td>7.801336</td>\n",
       "      <td>347.0</td>\n",
       "      <td>0.510086</td>\n",
       "      <td>0.512968</td>\n",
       "      <td>0.206278</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>3.084629e-05</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19632</th>\n",
       "      <td>......</td>\n",
       "      <td>5.792781</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1.207029e-05</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4717</th>\n",
       "      <td>toggle</td>\n",
       "      <td>6.984705</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.422414</td>\n",
       "      <td>0.491379</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>2.816401e-05</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4909</th>\n",
       "      <td>caption</td>\n",
       "      <td>6.207069</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.433121</td>\n",
       "      <td>0.484076</td>\n",
       "      <td>0.480916</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>4.224601e-05</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>Could</td>\n",
       "      <td>7.691330</td>\n",
       "      <td>312.0</td>\n",
       "      <td>0.403846</td>\n",
       "      <td>0.464744</td>\n",
       "      <td>0.118881</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>1.139972e-05</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>subscribe</td>\n",
       "      <td>6.719439</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.122388</td>\n",
       "      <td>0.444776</td>\n",
       "      <td>0.649573</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>5.096344e-05</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>notice</td>\n",
       "      <td>9.627829</td>\n",
       "      <td>358.0</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>0.424581</td>\n",
       "      <td>0.204188</td>\n",
       "      <td>191.0</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>2.615229e-05</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>subs</td>\n",
       "      <td>6.335531</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.944658e-05</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>m</td>\n",
       "      <td>6.461119</td>\n",
       "      <td>262.0</td>\n",
       "      <td>0.404580</td>\n",
       "      <td>0.408397</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>1.207029e-05</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12357</th>\n",
       "      <td>high-</td>\n",
       "      <td>7.661068</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.328358</td>\n",
       "      <td>0.388060</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.207029e-05</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12402</th>\n",
       "      <td>quality</td>\n",
       "      <td>14.772954</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.676429e-05</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12360</th>\n",
       "      <td>models</td>\n",
       "      <td>7.079657</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>4.694001e-05</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12238</th>\n",
       "      <td>publications</td>\n",
       "      <td>9.733078</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>4.023430e-06</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8715</th>\n",
       "      <td>orn</td>\n",
       "      <td>12.492856</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.340782</td>\n",
       "      <td>0.346369</td>\n",
       "      <td>0.551471</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>5.029287e-05</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4492</th>\n",
       "      <td>traditional</td>\n",
       "      <td>8.096800</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.330769</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1.005857e-05</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>receive</td>\n",
       "      <td>8.820920</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.408200e-05</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>,</td>\n",
       "      <td>6.073971</td>\n",
       "      <td>54532.0</td>\n",
       "      <td>0.125743</td>\n",
       "      <td>0.322893</td>\n",
       "      <td>0.935919</td>\n",
       "      <td>107006.0</td>\n",
       "      <td>0.220376</td>\n",
       "      <td>0.004562</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>6.715708e-02</td>\n",
       "      <td>0.036282</td>\n",
       "      <td>0.071755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6661</th>\n",
       "      <td>Op</td>\n",
       "      <td>10.974274</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>6.705716e-07</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966</th>\n",
       "      <td>programs</td>\n",
       "      <td>8.553944</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.309735</td>\n",
       "      <td>0.309735</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>2.749344e-05</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>offers</td>\n",
       "      <td>8.325966</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.291339</td>\n",
       "      <td>0.291339</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>6.035145e-06</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>the</td>\n",
       "      <td>6.263009</td>\n",
       "      <td>55766.0</td>\n",
       "      <td>0.153606</td>\n",
       "      <td>0.288671</td>\n",
       "      <td>0.946689</td>\n",
       "      <td>160681.0</td>\n",
       "      <td>0.232377</td>\n",
       "      <td>0.005699</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>1.020040e-01</td>\n",
       "      <td>0.037103</td>\n",
       "      <td>0.107748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word       loss  n_occurs  true_pos     top_k  false_pos   n_preds    loss_p    true_p    topk_p       false_p         p    pred_p\n",
       "363              See   3.188092     328.0  0.698171  0.743902   0.154982     271.0  0.000696  0.000152  0.000162  2.816401e-05  0.000218  0.000182\n",
       "4611             day   4.179189     145.0  0.731034  0.737931   0.595420     262.0  0.000403  0.000071  0.000071  1.046092e-04  0.000096  0.000176\n",
       "8708       delivered   4.856407     177.0  0.638418  0.638418   0.042373     118.0  0.000572  0.000075  0.000075  3.352858e-06  0.000118  0.000079\n",
       "3854      occasional   5.505368      67.0  0.597015  0.597015   0.375000      64.0  0.000245  0.000027  0.000027  1.609372e-05  0.000045  0.000043\n",
       "12336    sustainable   6.594767      59.0  0.593220  0.593220   0.186047      43.0  0.000259  0.000023  0.000023  5.364573e-06  0.000039  0.000029\n",
       "19670           ....   4.938991     121.0  0.272727  0.570248   0.365385      52.0  0.000398  0.000022  0.000046  1.274086e-05  0.000081  0.000035\n",
       "445          letters   7.628775      62.0  0.500000  0.564516   0.138889      36.0  0.000315  0.000021  0.000023  3.352858e-06  0.000041  0.000024\n",
       "418             Show   4.990631     275.0  0.523636  0.523636   0.521595     301.0  0.000913  0.000096  0.000096  1.052797e-04  0.000183  0.000202\n",
       "3804          promot   6.378230      71.0  0.521127  0.521127   0.212766      47.0  0.000301  0.000025  0.000025  6.705716e-06  0.000047  0.000032\n",
       "517          privacy   7.801336     347.0  0.510086  0.512968   0.206278     223.0  0.001801  0.000118  0.000118  3.084629e-05  0.000231  0.000150\n",
       "19632         ......   5.792781      99.0  0.191919  0.494949   0.486486      37.0  0.000382  0.000013  0.000033  1.207029e-05  0.000066  0.000025\n",
       "4717          toggle   6.984705     116.0  0.422414  0.491379   0.461538      91.0  0.000539  0.000033  0.000038  2.816401e-05  0.000077  0.000061\n",
       "4909         caption   6.207069     157.0  0.433121  0.484076   0.480916     131.0  0.000648  0.000045  0.000051  4.224601e-05  0.000104  0.000088\n",
       "739            Could   7.691330     312.0  0.403846  0.464744   0.118881     143.0  0.001597  0.000084  0.000096  1.139972e-05  0.000208  0.000096\n",
       "792        subscribe   6.719439     335.0  0.122388  0.444776   0.649573     117.0  0.001498  0.000027  0.000099  5.096344e-05  0.000223  0.000078\n",
       "0             notice   9.627829     358.0  0.424581  0.424581   0.204188     191.0  0.002293  0.000101  0.000101  2.615229e-05  0.000238  0.000128\n",
       "370             subs   6.335531      56.0  0.410714  0.410714   0.557692      52.0  0.000236  0.000015  0.000015  1.944658e-05  0.000037  0.000035\n",
       "7771               m   6.461119     262.0  0.404580  0.408397   0.145161     124.0  0.001126  0.000071  0.000071  1.207029e-05  0.000174  0.000083\n",
       "12357          high-   7.661068      67.0  0.328358  0.388060   0.450000      40.0  0.000342  0.000015  0.000017  1.207029e-05  0.000045  0.000027\n",
       "12402        quality  14.772954      63.0  0.380952  0.380952   0.510204      49.0  0.000619  0.000016  0.000016  1.676429e-05  0.000042  0.000033\n",
       "12360         models   7.079657     104.0  0.365385  0.375000   0.648148     108.0  0.000490  0.000025  0.000026  4.694001e-05  0.000069  0.000072\n",
       "12238   publications   9.733078      56.0  0.375000  0.375000   0.222222      27.0  0.000363  0.000014  0.000014  4.023430e-06  0.000037  0.000018\n",
       "8715             orn  12.492856     179.0  0.340782  0.346369   0.551471     136.0  0.001488  0.000041  0.000041  5.029287e-05  0.000119  0.000091\n",
       "4492     traditional   8.096800     130.0  0.330769  0.330769   0.258621      58.0  0.000700  0.000029  0.000029  1.005857e-05  0.000086  0.000039\n",
       "1867         receive   8.820920     122.0  0.327869  0.327869   0.344262      61.0  0.000716  0.000027  0.000027  1.408200e-05  0.000081  0.000041\n",
       "11                 ,   6.073971   54532.0  0.125743  0.322893   0.935919  107006.0  0.220376  0.004562  0.011715  6.715708e-02  0.036282  0.071755\n",
       "6661              Op  10.974274      56.0  0.321429  0.321429   0.052632      19.0  0.000409  0.000012  0.000012  6.705716e-07  0.000037  0.000013\n",
       "3966        programs   8.553944     113.0  0.309735  0.309735   0.539474      76.0  0.000643  0.000023  0.000023  2.749344e-05  0.000075  0.000051\n",
       "1501          offers   8.325966     127.0  0.291339  0.291339   0.195652      46.0  0.000704  0.000025  0.000025  6.035145e-06  0.000084  0.000031\n",
       "188              the   6.263009   55766.0  0.153606  0.288671   0.946689  160681.0  0.232377  0.005699  0.010711  1.020040e-01  0.037103  0.107748"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_occurs = 50\n",
    "df.loc[df[\"n_occurs\"]>n_occurs].sort_values(by=\"top_k\", ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41ab567b-c26a-48fa-ae8f-fa123dea8545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word', 'loss', 'n_occurs', 'true_pos', 'top_k', 'false_pos', 'n_preds', 'loss_p', 'true_p', 'topk_p', 'false_p', 'p', 'pred_p'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60cccca7-494c-405a-95e0-9250ab507dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word & Avg Loss & Top 1 & Top 5 & p(Word) & False Pos & p(Pred) & Loss P & Flse Pos Rate \\\\\n",
      "\\hline\\hline\n",
      " the & 6.263 & 0.154 & 0.289 & 0.037 & 0.947 & 0.108 & 0.232 & 0.102 \\\\\n",
      "\\hline\n",
      ", & 6.074 & 0.126 & 0.323 & 0.036 & 0.936 & 0.072 & 0.22 & 0.067 \\\\\n",
      "\\hline\n",
      " a & 6.63 & 0.077 & 0.247 & 0.019 & 0.963 & 0.039 & 0.126 & 0.038 \\\\\n",
      "\\hline\n",
      " of & 7.331 & 0.082 & 0.152 & 0.021 & 0.952 & 0.036 & 0.151 & 0.034 \\\\\n",
      "\\hline\n",
      ". & 6.974 & 0.075 & 0.217 & 0.021 & 0.945 & 0.029 & 0.149 & 0.028 \\\\\n",
      "\\hline\n",
      " and & 6.128 & 0.049 & 0.254 & 0.016 & 0.971 & 0.027 & 0.095 & 0.026 \\\\\n",
      "\\hline\n",
      " to & 6.875 & 0.069 & 0.142 & 0.019 & 0.946 & 0.025 & 0.134 & 0.024 \\\\\n",
      "\\hline\n",
      " in & 6.5 & 0.04 & 0.179 & 0.015 & 0.966 & 0.017 & 0.096 & 0.017 \\\\\n",
      "\\hline\n",
      "\\textbackslash n \\textbackslash n  & 6.921 & 0.139 & 0.241 & 0.007 & 0.935 & 0.015 & 0.05 & 0.014 \\\\\n",
      "\\hline\n",
      "The & 13.952 & 0.061 & 0.073 & 0.003 & 0.986 & 0.013 & 0.043 & 0.013 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "keys = ['loss', 'true_pos', 'top_k',  'p', 'false_pos', 'pred_p', 'loss_p', \"false_p\"]\n",
    "template = len(keys)*\"{} & \"\n",
    "template = template[:-2]\n",
    "\n",
    "s = \"Word & Avg Loss & Top 1 & Top 5 & p(Word) & False Pos & p(Pred) & Loss P & Flse Pos Rate \\\\\\\\\"\n",
    "print(s)\n",
    "print(\"\\\\hline\\\\hline\")\n",
    "sfigs = 3\n",
    "t = df.sort_values(by=\"false_p\", ascending=False).head(10)\n",
    "for row in range(len(t)):\n",
    "    word = t[\"word\"].iloc[row]\n",
    "    s = word + \" & \" + template.format( *[round(t[k].iloc[row], sfigs) for k in keys] ) + \"\\\\\"\n",
    "    print(repr(s)[1:-1].replace(\"\\\\n\",\"\\\\textbackslash n \"))\n",
    "    print(\"\\\\hline\")\n",
    "    #print(s + \" \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1ca7b0a-66ce-4742-8bed-a8d23862845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word & Avg Loss & Top 1 & Top 5 & p(Word) & False Pos & p(Pred) & Loss P & Flse Pos Rate \\\\\n",
      "\\hline\\hline\n",
      " Punt & 25.539 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
      "\\hline\n",
      "erria & 22.722 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
      "\\hline\n",
      "Register & 16.189 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
      "\\hline\n",
      " Suk & 15.415 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
      "\\hline\n",
      "384 & 26.916 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
      "\\hline\n",
      "Impro & 29.48 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
      "\\hline\n",
      "_text & 14.116 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
      "\\hline\n",
      " Gaud & 15.672 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
      "\\hline\n",
      " Dro & 13.524 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
      "\\hline\n",
      "Address & 19.083 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
      "\\hline\n"
     ]
    }
   ],
   "source": [
    "keys = ['loss', 'true_pos', 'top_k',  'p', 'false_pos', 'pred_p', 'loss_p', \"false_p\"]\n",
    "template = len(keys)*\"{} & \"\n",
    "template = template[:-2]\n",
    "\n",
    "s = \"Word & Avg Loss & Top 1 & Top 5 & p(Word) & False Pos & p(Pred) & Loss P & Flse Pos Rate \\\\\\\\\"\n",
    "print(s)\n",
    "print(\"\\\\hline\\\\hline\")\n",
    "sfigs = 3\n",
    "t = df.sort_values(by=\"false_p\", ascending=True).head(10)\n",
    "for row in range(len(t)):\n",
    "    word = t[\"word\"].iloc[row]\n",
    "    s = word + \" & \" + template.format( *[round(t[k].iloc[row], sfigs) for k in keys] ) + \"\\\\\"\n",
    "    print(repr(s)[1:-1].replace(\"\\\\n\",\"\\\\textbackslash n \"))\n",
    "    print(\"\\\\hline\")\n",
    "    #print(s + \" \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c96ff0a-e3b9-47c3-96d6-f0b4e794f429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93fccc8c-8f0e-4f8a-8c5d-818310e7a214",
   "metadata": {},
   "source": [
    "### True Positives Top 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "172b6015-0adc-4a7d-9d06-3f0846f14924",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_tps = dict()\n",
    "tps_list = []\n",
    "for k in top1_tps.keys():\n",
    "    name = tokenizer.decode(k)\n",
    "    named_tps[name] = top1_tps[k][0]/top1_tps[k][1]\n",
    "    tps_list.append([name, named_tps[name], top1_tps[k][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ddabc19-06b8-48c9-99ea-2ff34a3c3dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['り', 1.0, 1.0],\n",
       " [' países', 1.0, 1.0],\n",
       " [' inhibitor', 1.0, 1.0],\n",
       " [' ст', 1.0, 1.0],\n",
       " ['oscope', 1.0, 1.0],\n",
       " [' receptor', 1.0, 1.0],\n",
       " ['ucle', 1.0, 1.0],\n",
       " [' �', 1.0, 1.0],\n",
       " [' Nevertheless', 0.88, 50.0],\n",
       " ['day', 0.7310344827586207, 145.0],\n",
       " [' See', 0.698170731707317, 328.0],\n",
       " ['push', 0.6666666666666666, 9.0],\n",
       " [' delivered', 0.6384180790960452, 177.0],\n",
       " [' invalid', 0.6086956521739131, 46.0],\n",
       " [' occasional', 0.5970149253731343, 67.0],\n",
       " [' sustainable', 0.5932203389830508, 59.0],\n",
       " ['cribing', 0.5806451612903226, 31.0],\n",
       " [' Show', 0.5236363636363637, 275.0],\n",
       " [' promot', 0.5211267605633803, 71.0],\n",
       " [' privacy', 0.5100864553314121, 347.0]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list = sorted(tps_list, key=lambda x: -x[1])\n",
    "temp_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bf995ce-ed22-40e6-8fea-eab57926a23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' países', 1.0, 1.0],\n",
       " [' inhibitor', 1.0, 1.0],\n",
       " [' ст', 1.0, 1.0],\n",
       " [' receptor', 1.0, 1.0],\n",
       " [' �', 1.0, 1.0],\n",
       " [' delivered', 0.6384180790960452, 177.0],\n",
       " [' invalid', 0.6086956521739131, 46.0],\n",
       " [' occasional', 0.5970149253731343, 67.0],\n",
       " [' sustainable', 0.5932203389830508, 59.0],\n",
       " [' promot', 0.5211267605633803, 71.0],\n",
       " [' privacy', 0.5100864553314121, 347.0],\n",
       " [' transported', 0.5, 2.0],\n",
       " [' caption', 0.43312101910828027, 157.0],\n",
       " [' notice', 0.4245810055865922, 358.0],\n",
       " [' toggle', 0.4224137931034483, 116.0],\n",
       " [' subs', 0.4107142857142857, 56.0],\n",
       " [' m', 0.40458015267175573, 262.0],\n",
       " [' publications', 0.375, 56.0],\n",
       " [' models', 0.36538461538461536, 104.0],\n",
       " [' spelling', 0.3333333333333333, 3.0]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_words = list(filter(lambda x: x[0][0]==\" \" and len(x[0])>1 and not x[0][1].isupper(), temp_list))\n",
    "full_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "815a4080-8e54-43ad-92f5-fa472221f12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' the', 0.1536061399419001, 55766.0],\n",
       " [' of', 0.08229321606415314, 30926.0],\n",
       " [' to', 0.06927751980333242, 29288.0],\n",
       " [' a', 0.07717967625267741, 28479.0],\n",
       " [' and', 0.04868673926969891, 23415.0],\n",
       " [' in', 0.03997836570964979, 22187.0],\n",
       " [' on', 0.022530482417388233, 11318.0],\n",
       " [' for', 0.024795665350353567, 10889.0],\n",
       " [' that', 0.03506481395131959, 10723.0],\n",
       " [' is', 0.06383574428371441, 10715.0],\n",
       " [' with', 0.023721176782401272, 7546.0],\n",
       " [' was', 0.045187601957585644, 6130.0],\n",
       " [' has', 0.021203155818540435, 6084.0],\n",
       " [' at', 0.010394324368916021, 6061.0],\n",
       " [' as', 0.016960886119764623, 5778.0],\n",
       " [' by', 0.022707269846857947, 5681.0],\n",
       " [' it', 0.01335981224047662, 5539.0],\n",
       " [' from', 0.02266615443718786, 5206.0],\n",
       " [' are', 0.04880603267700042, 4774.0],\n",
       " [' an', 0.003401360544217687, 4704.0]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(full_words, key=lambda x: -x[-1])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db6a88-1e41-46d5-a3ba-96efb29c3707",
   "metadata": {},
   "source": [
    "### True Positives Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf40dee-24ea-4955-83ce-bcc5c5abf441",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_tps = dict()\n",
    "tps_list = []\n",
    "for k in topn_tps.keys():\n",
    "    name = tokenizer.decode(k)\n",
    "    named_tps[name] = topn_tps[k][0]/topn_tps[k][1]\n",
    "    tps_list.append([name, named_tps[name], topn_tps[k][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e63ad2-9bad-425a-9aa4-acaaeb9ac253",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = sorted(tps_list, key=lambda x: -x[1])\n",
    "temp_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd66045-4d07-4603-b89f-87946fd6e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_words = list(filter(lambda x: x[0][0]==\" \" and len(x[0])>1 and not x[0][1].isupper(), temp_list))\n",
    "full_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212a356-0d77-4de1-83ad-969dd97759cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(full_words, key=lambda x: -x[-1])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd450cc-b61c-478a-912c-5ba84b398c6c",
   "metadata": {},
   "source": [
    "### False Positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f294f742-6225-4f73-894f-f274b51d5b57",
   "metadata": {},
   "source": [
    "The rates in the middle column are out of all the times that the model predicts that token, what proportion are incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98f8b61-2443-49ca-af75-1b62059289dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_fps = dict()\n",
    "fps_list = []\n",
    "for k in top1_fps.keys():\n",
    "    name = tokenizer.decode(k)\n",
    "    named_fps[name] = top1_fps[k][0]/top1_fps[k][1]\n",
    "    fps_list.append([name, named_fps[name], top1_fps[k][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5bce6f-688a-4ebb-b1be-7cd441cb893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = sorted(fps_list, key=lambda x: x[1])\n",
    "temp_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c02496d-7545-4cc9-8f0d-6c337d92189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_words = list(filter(lambda x: x[0][0]==\" \" and len(x[0])>1 and not x[0][1].isupper(), temp_list))\n",
    "full_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc1cea-d523-4877-9ae0-d6e46aa524bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(full_words, key=lambda x: -x[-1])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d88ee0-c39d-4cf5-aade-a92dca9b3f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebdb7bb-d7ee-4909-bf3c-3ab57fa2c935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb27977e-9c76-4b67-8ca7-48a77f334a64",
   "metadata": {},
   "source": [
    "### Teacher Forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea1093af-b577-4123-be62-c43d2ae23d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 5\n",
    "max_loops = 1000\n",
    "tforce = False\n",
    "model.rmb_task = False\n",
    "lossfxn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "loss_avgs = collections.defaultdict(lambda: [0,0])\n",
    "top1_tps = collections.defaultdict(lambda:  [0,0])\n",
    "top1_fps = collections.defaultdict(lambda:  [0,0])\n",
    "topn_tps = collections.defaultdict(lambda:  [0,0])\n",
    "avg_loss = 0\n",
    "avg_acc = 0\n",
    "avg_fps = 0\n",
    "avg_topn = 0\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(valloader):\n",
    "        if not hyps[\"model_parallel\"]:\n",
    "            data = {k: v.to(model.get_device()) for k,v in data.items()}\n",
    "        preds = model(data, tforce=tforce)\n",
    "        preds = preds.reshape(-1,preds.shape[-1])\n",
    "        idx = data[\"output_attn_mask\"].reshape(-1).bool()\n",
    "        preds = preds[idx]\n",
    "        targs = data[\"output_ids\"].reshape(-1)[idx]\n",
    "        losses = lossfxn(preds, targs)\n",
    "        avg_loss += losses.mean().item()\n",
    "        \n",
    "        for id_ in set(targs.data.cpu().tolist()):\n",
    "            loss_avgs[id_][0] += losses[targs==id_].sum().item()\n",
    "            loss_avgs[id_][1] += (targs==id_).float().sum().item()\n",
    "            \n",
    "        args = torch.argsort(preds, dim=-1)[:,-top_n:]\n",
    "        top1 = args[:,-1]\n",
    "        avg_acc += (top1==targs).float().mean().item()\n",
    "        avg_topn += (args==targs[:,None]).float().mean().item()\n",
    "        for id_ in set(set(targs.data.cpu().tolist())):\n",
    "            idx = targs==id_\n",
    "            s = idx.float().sum().item()\n",
    "            top1_tps[id_][0] += (top1[idx]==targs[idx]).float().sum().item()\n",
    "            top1_tps[id_][1] += s\n",
    "            \n",
    "            topn_tps[id_][0] += (args[idx]==targs[idx][:,None]).float().sum().item()\n",
    "            topn_tps[id_][1] += s\n",
    "            \n",
    "        for id_ in set(top1.data.cpu().tolist()):\n",
    "            idx = top1==id_\n",
    "            top1_fps[id_][0] += (top1[idx]!=targs[idx]).float().sum().item()\n",
    "            top1_fps[id_][1] += idx.float().sum().item()\n",
    "            \n",
    "        if i>max_loops: break\n",
    "\n",
    "print(\"Avg Loss:\", round(avg_loss/(i+1), 5))\n",
    "print(\"Avg Top 1:\", round(avg_acc/(i+1), 5))\n",
    "print(\"Avg Top {}:\".format(top_n), round(avg_topn/(i+1), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca33330-440b-439d-aa69-cd9d97ffb72b",
   "metadata": {},
   "source": [
    "### Loss Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9581f647-0807-4a6e-baa0-de3042570785",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_loss_avgs = dict()\n",
    "sort_list = []\n",
    "for k in loss_avgs.keys():\n",
    "    name = tokenizer.decode(k)\n",
    "    named_loss_avgs[name] = loss_avgs[k][0]/loss_avgs[k][1]\n",
    "    sort_list.append([name, named_loss_avgs[name], loss_avgs[k][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "393b9f79-80cd-4d26-bdb1-865683a1ae2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NGL', 0.0, 1.0],\n",
       " ['agwa', 1.867608448928119e-06, 3.0],\n",
       " ['iably', 3.6954811548639555e-06, 1.0],\n",
       " ['arta', 1.4066597032069694e-05, 1.0],\n",
       " ['fron', 1.484143558627693e-05, 2.0],\n",
       " ['kusen', 2.048627863717099e-05, 7.0],\n",
       " ['ubali', 2.658331868587993e-05, 1.0],\n",
       " [' Bartomeu', 3.266281055402942e-05, 1.0],\n",
       " ['iquet', 3.862306402879767e-05, 1.0],\n",
       " ['-tête', 4.2199197196168825e-05, 1.0],\n",
       " ['uruza', 5.006664650863968e-05, 1.0],\n",
       " ['ongwe', 5.924526340095326e-05, 1.0],\n",
       " [' Valls', 6.752907211193815e-05, 2.0],\n",
       " ['anean', 9.524224515189417e-05, 2.0],\n",
       " ['ongyang', 0.0001294529065489769, 1.0],\n",
       " ['peer', 0.00018113236510544083, 5.0],\n",
       " [' Chapo', 0.00020251607929822057, 1.0],\n",
       " ['erosis', 0.0002118443032183374, 3.0],\n",
       " [' Verdes', 0.00023600654094479978, 1.0],\n",
       " ['ukee', 0.00024232311989180744, 1.0]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_list = sorted(sort_list, key=lambda x: x[1])\n",
    "loss_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d055287-64ee-4b98-b055-3e57a17a9160",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' mater', 0.0012694318138528615, 2.0],\n",
       " [' thromb', 0.009309808723628521, 1.0],\n",
       " [' versa', 0.011989669874310493, 1.0],\n",
       " [' mujeres', 0.014297310262918472, 1.0],\n",
       " [' lugar', 0.017006753012537956, 1.0],\n",
       " [' spectr', 0.023944605141878128, 1.0],\n",
       " [' রহমান', 0.025047944858670235, 1.0],\n",
       " [' passe', 0.02992119826376438, 1.0],\n",
       " [' gangl', 0.03146141767501831, 1.0],\n",
       " [' culpa', 0.032384321093559265, 1.0],\n",
       " [' peso', 0.07188235968351364, 1.0],\n",
       " [' sociales', 0.07857572287321091, 1.0],\n",
       " [' nova', 0.08306349068880081, 1.0],\n",
       " [' align=\"', 0.11585231125354767, 1.0],\n",
       " [' général', 0.14817063510417938, 1.0],\n",
       " [' contexto', 0.1590195745229721, 1.0],\n",
       " [' من', 0.16336815059185028, 1.0],\n",
       " [' bandera', 0.19541625678539276, 1.0],\n",
       " [' sapiens', 0.21687181293964386, 2.0],\n",
       " [' sécurité', 0.233374185860157, 2.0]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_words = list(filter(lambda x: x[0][0]==\" \" and len(x[0])>1 and not x[0][1].isupper(), loss_list))\n",
    "full_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99f5ce0b-024b-458a-a29b-ff77a43f0d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' the', 1.6798055604684536, 68652.0],\n",
       " [' of', 1.0945485224302465, 41001.0],\n",
       " [' a', 2.0942610431373825, 38722.0],\n",
       " [' to', 1.544669320361295, 36775.0],\n",
       " [' in', 2.47927663671508, 29467.0],\n",
       " [' and', 2.6678868049178384, 27302.0],\n",
       " [' on', 2.8296480845647762, 15868.0],\n",
       " [' is', 2.782925840363093, 15814.0],\n",
       " [' for', 2.532189460657359, 15725.0],\n",
       " [' that', 2.6700276598478743, 13103.0],\n",
       " [' with', 2.7525630139888864, 9535.0],\n",
       " [' has', 3.4473087286280695, 9416.0],\n",
       " [' at', 3.544092822363648, 8009.0],\n",
       " [' by', 2.9226989666642655, 7759.0],\n",
       " [' was', 2.841507685407055, 7284.0],\n",
       " [' as', 3.1476076638179817, 6891.0],\n",
       " [' have', 2.8802782918492884, 6876.0],\n",
       " [' (', 3.9449549322095416, 6671.0],\n",
       " [' from', 2.9189033698587807, 6668.0],\n",
       " [' an', 3.9189066886529154, 6397.0]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(full_words, key=lambda x: -x[-1])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77898677-23f2-4260-b8c6-338fa89c4caf",
   "metadata": {},
   "source": [
    "### True Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0a49f94-b81b-4446-b4c9-986fc3163635",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_tps = dict()\n",
    "tps_list = []\n",
    "for k in top1_tps.keys():\n",
    "    name = tokenizer.decode(k)\n",
    "    named_tps[name] = top1_tps[k][0]/top1_tps[k][1]\n",
    "    tps_list.append([name, named_tps[name], top1_tps[k][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fce757a7-1365-4cd6-91d8-a907ca2f0da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['kur', 1.0, 1.0],\n",
       " ['atie', 1.0, 3.0],\n",
       " ['bons', 1.0, 5.0],\n",
       " ['ónica', 1.0, 1.0],\n",
       " [' sociales', 1.0, 1.0],\n",
       " ['ministration', 1.0, 1.0],\n",
       " ['akis', 1.0, 6.0],\n",
       " ['oise', 1.0, 9.0],\n",
       " [' Verdes', 1.0, 1.0],\n",
       " ['gravity', 1.0, 2.0],\n",
       " ['itano', 1.0, 7.0],\n",
       " ['ipotent', 1.0, 1.0],\n",
       " ['み', 1.0, 1.0],\n",
       " ['ortium', 1.0, 16.0],\n",
       " ['etermin', 1.0, 1.0],\n",
       " ['ansk', 1.0, 7.0],\n",
       " ['letion', 1.0, 2.0],\n",
       " ['edan', 1.0, 1.0],\n",
       " [' class=\"', 1.0, 2.0],\n",
       " ['establ', 1.0, 4.0]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list = sorted(tps_list, key=lambda x: -x[1])\n",
    "temp_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fe08fac-1fea-4aca-95ca-20a8ddcc8ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' sociales', 1.0, 1.0],\n",
       " [' class=\"', 1.0, 2.0],\n",
       " [' in\"', 1.0, 1.0],\n",
       " [' masse', 1.0, 4.0],\n",
       " [' bandera', 1.0, 1.0],\n",
       " [' passe', 1.0, 1.0],\n",
       " [' rapporteur', 1.0, 1.0],\n",
       " [' culpa', 1.0, 1.0],\n",
       " [\" d'Ivoire\", 1.0, 1.0],\n",
       " [' firma', 1.0, 1.0],\n",
       " [' mí', 1.0, 1.0],\n",
       " [' prix', 1.0, 2.0],\n",
       " [' voir', 1.0, 1.0],\n",
       " [' mell', 1.0, 1.0],\n",
       " [' familias', 1.0, 1.0],\n",
       " [' vista', 1.0, 1.0],\n",
       " [' daño', 1.0, 1.0],\n",
       " [' général', 1.0, 1.0],\n",
       " [' peso', 1.0, 1.0],\n",
       " [' générale', 1.0, 1.0]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_words = list(filter(lambda x: x[0][0]==\" \" and len(x[0])>1 and not x[0][1].isupper(), temp_list))\n",
    "full_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee6acfa1-7bbd-4f9b-b439-5970667e77d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' the', 0.6926964982811863, 68652.0],\n",
       " [' of', 0.7813955757176654, 41001.0],\n",
       " [' a', 0.48915345281751976, 38722.0],\n",
       " [' to', 0.6490550645819171, 36775.0],\n",
       " [' in', 0.35904571215257747, 29467.0],\n",
       " [' and', 0.24111786682294337, 27302.0],\n",
       " [' on', 0.274136627174187, 15868.0],\n",
       " [' is', 0.34659162767168333, 15814.0],\n",
       " [' for', 0.3785055643879173, 15725.0],\n",
       " [' that', 0.375410211401969, 13103.0],\n",
       " [' with', 0.36717357105401155, 9535.0],\n",
       " [' has', 0.17162276975361088, 9416.0],\n",
       " [' at', 0.1649394431264827, 8009.0],\n",
       " [' by', 0.3707952055677278, 7759.0],\n",
       " [' was', 0.3698517298187809, 7284.0],\n",
       " [' as', 0.31011464228704105, 6891.0],\n",
       " [' have', 0.2799592786503781, 6876.0],\n",
       " [' (', 0.1630939889072103, 6671.0],\n",
       " [' from', 0.34148170365926817, 6668.0],\n",
       " [' an', 0.007034547444114429, 6397.0]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(full_words, key=lambda x: -x[-1])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0815c5ee-9f01-40f5-8a5b-faeec8d4489d",
   "metadata": {},
   "source": [
    "### True Positives Top N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "390a29bd-d6c9-40a8-b722-56c1ff5d28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_tps = dict()\n",
    "tps_list = []\n",
    "for k in topn_tps.keys():\n",
    "    name = tokenizer.decode(k)\n",
    "    named_tps[name] = topn_tps[k][0]/topn_tps[k][1]\n",
    "    tps_list.append([name, named_tps[name], topn_tps[k][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2a3ab83-147e-43ab-aa41-de765d343af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' galaxies', 1.0, 1.0],\n",
       " [',', 0.3383961595970725, 25414.0],\n",
       " ['ang-', 0.3333333333333333, 3.0],\n",
       " [' genus', 0.3333333333333333, 3.0],\n",
       " ['ulls', 0.3333333333333333, 3.0],\n",
       " [' the', 0.2650908956819942, 27119.0],\n",
       " ['FBI', 0.25, 4.0],\n",
       " [' a', 0.23732264844981607, 15224.0],\n",
       " [' and', 0.21154562383612663, 10740.0],\n",
       " ['ortium', 0.2, 5.0],\n",
       " [' Figure', 0.2, 5.0],\n",
       " ['\\n\\n', 0.17294356129307586, 9373.0],\n",
       " ['je', 0.16666666666666666, 6.0],\n",
       " [' in', 0.1548722390645301, 11545.0],\n",
       " ['ovich', 0.14285714285714285, 7.0],\n",
       " ['qq', 0.14285714285714285, 7.0],\n",
       " [' of', 0.13908697507161577, 16407.0],\n",
       " [' is', 0.13086097042966835, 6121.0],\n",
       " ['.', 0.12654344658332695, 13039.0],\n",
       " [' glasses', 0.125, 8.0]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list = sorted(tps_list, key=lambda x: -x[1])\n",
    "temp_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc824b4c-74fc-4e79-a9bc-a5080c6eb1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' galaxies', 1.0, 1.0],\n",
       " [' genus', 0.3333333333333333, 3.0],\n",
       " [' the', 0.2650908956819942, 27119.0],\n",
       " [' a', 0.23732264844981607, 15224.0],\n",
       " [' and', 0.21154562383612663, 10740.0],\n",
       " [' in', 0.1548722390645301, 11545.0],\n",
       " [' of', 0.13908697507161577, 16407.0],\n",
       " [' is', 0.13086097042966835, 6121.0],\n",
       " [' glasses', 0.125, 8.0],\n",
       " [' vegetables', 0.125, 8.0],\n",
       " [' galaxy', 0.1111111111111111, 9.0],\n",
       " [' pregnancy', 0.1111111111111111, 9.0],\n",
       " [' --', 0.1044776119402985, 536.0],\n",
       " [' to', 0.10292178499548893, 14409.0],\n",
       " [' cheese', 0.09090909090909091, 11.0],\n",
       " [' on', 0.07765426131786693, 6207.0],\n",
       " [' video', 0.07435897435897436, 390.0],\n",
       " [' —', 0.07395498392282958, 933.0],\n",
       " [' (', 0.07380073800738007, 2710.0],\n",
       " [' version', 0.07317073170731707, 123.0]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_words = list(filter(lambda x: x[0][0]==\" \" and len(x[0])>1 and not x[0][1].isupper(), temp_list))\n",
    "full_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d1b6727-8967-43bd-a81f-28a8758667d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' the', 0.2650908956819942, 27119.0],\n",
       " [' of', 0.13908697507161577, 16407.0],\n",
       " [' a', 0.23732264844981607, 15224.0],\n",
       " [' to', 0.10292178499548893, 14409.0],\n",
       " [' in', 0.1548722390645301, 11545.0],\n",
       " [' and', 0.21154562383612663, 10740.0],\n",
       " [' for', 0.06059634498236614, 6238.0],\n",
       " [' on', 0.07765426131786693, 6207.0],\n",
       " [' is', 0.13086097042966835, 6121.0],\n",
       " [' that', 0.06014450302675259, 5121.0],\n",
       " [' with', 0.023613399231191653, 3642.0],\n",
       " [' has', 0.0494641384995878, 3639.0],\n",
       " [' at', 0.019143413367942893, 3082.0],\n",
       " [' by', 0.017774851876234364, 3038.0],\n",
       " [' was', 0.061196105702364396, 2876.0],\n",
       " [' as', 0.0164638511095204, 2794.0],\n",
       " [' (', 0.07380073800738007, 2710.0],\n",
       " [' from', 0.03897550111358575, 2694.0],\n",
       " [' have', 0.05606060606060606, 2640.0],\n",
       " [' are', 0.04821638573108585, 2551.0]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(full_words, key=lambda x: -x[-1])[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24278e79-b4a2-4ca1-9121-763641fc5566",
   "metadata": {},
   "source": [
    "### False Positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a8f69e-b716-4a9b-b8d3-10c569d86972",
   "metadata": {},
   "source": [
    "The rates in the middle column are out of all the times that the model predicts that token, what proportion are incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50b0bfd3-26d1-4c86-bc5f-8c9eb788143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_fps = dict()\n",
    "fps_list = []\n",
    "for k in top1_fps.keys():\n",
    "    name = tokenizer.decode(k)\n",
    "    named_fps[name] = top1_fps[k][0]/top1_fps[k][1]\n",
    "    fps_list.append([name, named_fps[name], top1_fps[k][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4444be44-b20e-4b3e-860c-129fbd8c2ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['70', 0.0, 1.0],\n",
       " ['heastern', 0.0, 28.0],\n",
       " ['kur', 0.0, 1.0],\n",
       " [' sponsors', 0.0, 1.0],\n",
       " [' Becker', 0.0, 1.0],\n",
       " ['aguer', 0.0, 8.0],\n",
       " ['zor', 0.0, 2.0],\n",
       " ['ónica', 0.0, 1.0],\n",
       " [' sociales', 0.0, 1.0],\n",
       " ['ministration', 0.0, 1.0],\n",
       " ['akis', 0.0, 6.0],\n",
       " [' probability', 0.0, 1.0],\n",
       " [' Bil', 0.0, 1.0],\n",
       " [' hecho', 0.0, 1.0],\n",
       " ['ar\"', 0.0, 2.0],\n",
       " ['ynam', 0.0, 1.0],\n",
       " [' Verdes', 0.0, 1.0],\n",
       " ['tices', 0.0, 15.0],\n",
       " ['cend', 0.0, 1.0],\n",
       " ['usp', 0.0, 4.0]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_list = sorted(fps_list, key=lambda x: x[1])\n",
    "temp_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8b78be9-ed0c-4a68-b598-81fae440f7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' sponsors', 0.0, 1.0],\n",
       " [' sociales', 0.0, 1.0],\n",
       " [' probability', 0.0, 1.0],\n",
       " [' hecho', 0.0, 1.0],\n",
       " [' lup', 0.0, 1.0],\n",
       " [' insp', 0.0, 1.0],\n",
       " [' anime', 0.0, 4.0],\n",
       " [' soy', 0.0, 3.0],\n",
       " [' goth', 0.0, 1.0],\n",
       " [' in\"', 0.0, 1.0],\n",
       " [' 36', 0.0, 1.0],\n",
       " [' yen', 0.0, 1.0],\n",
       " [' premiere', 0.0, 5.0],\n",
       " [' 521', 0.0, 1.0],\n",
       " [' translation', 0.0, 1.0],\n",
       " [' lobster', 0.0, 1.0],\n",
       " [' rus', 0.0, 1.0],\n",
       " [\" 'em\", 0.0, 1.0],\n",
       " [' mutil', 0.0, 5.0],\n",
       " [' estimate', 0.0, 2.0]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_words = list(filter(lambda x: x[0][0]==\" \" and len(x[0])>1 and not x[0][1].isupper(), temp_list))\n",
    "full_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ec2a4ca-b3c3-4111-b241-766a683a54b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' the', 0.7645267510088881, 201955.0],\n",
       " [' a', 0.7752076904818419, 84260.0],\n",
       " [' of', 0.5341485757492039, 68773.0],\n",
       " [' to', 0.49657266994284266, 47413.0],\n",
       " [' in', 0.7195716709075488, 37728.0],\n",
       " [' is', 0.8500902576445489, 36562.0],\n",
       " [' and', 0.7950242869597708, 32116.0],\n",
       " [' be', 0.7507987220447284, 17215.0],\n",
       " [' for', 0.63896639572971, 16486.0],\n",
       " [' on', 0.717367292573582, 15391.0],\n",
       " [' been', 0.7671359031706354, 15202.0],\n",
       " [' was', 0.8102014935888403, 14194.0],\n",
       " [' that', 0.6369741697416974, 13550.0],\n",
       " [' new', 0.8869868441908385, 12618.0],\n",
       " [' are', 0.8081258411843876, 11888.0],\n",
       " [' have', 0.8319657821229051, 11456.0],\n",
       " [' first', 0.8929762169370972, 8998.0],\n",
       " [' has', 0.8115012247754578, 8573.0],\n",
       " [' from', 0.7052045572242361, 7724.0],\n",
       " [' with', 0.5341317365269461, 7515.0]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(full_words, key=lambda x: -x[-1])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eedf2f0-b403-4c6f-9cb1-fd7000fbb78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea5c466-c8ad-4d41-8051-42f3f16c8d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
