{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3913db94-e409-407e-a6e7-8a28b0ff6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPT2Tokenizer, GPTJForCausalLM, DataCollatorWithPadding\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07766e72-08e3-400c-aed3-25c9b69365c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hf-internal-testing/tiny-random-gptj were not used when initializing GPTJForCausalLM: ['h.1.attn.bias', 'h.1.attn.v_proj.weight', 'h.4.ln_1.bias', 'h.3.ln_1.weight', 'h.0.mlp.fc_out.weight', 'h.1.ln_1.weight', 'h.0.attn.q_proj.weight', 'h.2.mlp.fc_in.weight', 'h.3.attn.k_proj.weight', 'wte.weight', 'h.1.attn.q_proj.weight', 'h.0.attn.bias', 'ln_f.bias', 'h.2.attn.bias', 'h.4.mlp.fc_out.weight', 'h.4.attn.masked_bias', 'h.4.attn.k_proj.weight', 'h.0.ln_1.weight', 'h.3.attn.out_proj.weight', 'h.4.mlp.fc_out.bias', 'h.1.mlp.fc_out.bias', 'h.2.attn.masked_bias', 'h.3.attn.bias', 'h.1.attn.masked_bias', 'h.1.mlp.fc_in.weight', 'h.0.attn.v_proj.weight', 'h.1.mlp.fc_in.bias', 'h.0.mlp.fc_in.weight', 'h.0.attn.out_proj.weight', 'h.2.mlp.fc_out.bias', 'h.2.ln_1.bias', 'h.0.mlp.fc_in.bias', 'h.1.mlp.fc_out.weight', 'h.4.attn.q_proj.weight', 'score.weight', 'h.4.ln_1.weight', 'h.2.attn.q_proj.weight', 'h.3.attn.masked_bias', 'h.4.mlp.fc_in.weight', 'h.1.ln_1.bias', 'h.0.ln_1.bias', 'h.4.attn.bias', 'h.4.attn.v_proj.weight', 'h.3.attn.q_proj.weight', 'h.0.attn.masked_bias', 'h.2.mlp.fc_out.weight', 'ln_f.weight', 'h.0.mlp.fc_out.bias', 'h.2.attn.out_proj.weight', 'h.3.mlp.fc_out.weight', 'h.3.attn.v_proj.weight', 'h.1.attn.k_proj.weight', 'h.3.mlp.fc_in.weight', 'h.3.mlp.fc_out.bias', 'h.3.mlp.fc_in.bias', 'h.2.attn.v_proj.weight', 'h.2.attn.k_proj.weight', 'h.3.ln_1.bias', 'h.4.attn.out_proj.weight', 'h.4.mlp.fc_in.bias', 'h.0.attn.k_proj.weight', 'h.2.ln_1.weight', 'h.1.attn.out_proj.weight', 'h.2.mlp.fc_in.bias']\n",
      "- This IS expected if you are initializing GPTJForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPTJForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"hf-internal-testing/tiny-random-gptj\")\n",
    "\n",
    "hface_model = GPTJForCausalLM.from_pretrained(\"hf-internal-testing/tiny-random-gptj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a0573a3-8595-4f82-9995-92713bcf91d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTJForCausalLM(\n",
       "  (transformer): GPTJModel(\n",
       "    (wte): Embedding(1000, 32)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTJBlock(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (v_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (fc_out): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTJBlock(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (v_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (fc_out): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTJBlock(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (v_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (fc_out): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTJBlock(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (v_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (fc_out): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTJBlock(\n",
       "        (ln_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (v_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (q_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "          (out_proj): Linear(in_features=32, out_features=32, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (fc_out): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=32, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hface_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b193150-060c-4522-af88-9de5f1ac3088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ignore this for now\n",
    "#small_dataset = {\n",
    "#    \"rand\": {\n",
    "#        \"prompts\": [\n",
    "#            \"he's bald, he's mauled, he's called grindlewald... or so I'm tald.\",\n",
    "#            \"To win, you must move forward at all costs. There is no retreat. I get knocked down, but I get up again. You will never keep me down.\",\n",
    "#            \"Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam\", \n",
    "#            \"quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum\",\n",
    "#            \"dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\",\n",
    "#        ],\n",
    "#        \"answers\": [\n",
    "#            \"But why does the pilgrim seek refuge?\",\n",
    "#            \"Backoff, headstrong\",\n",
    "#            \"Sed ut perspiciatis unde omnis iste natus error\",\n",
    "#            \"sit voluptatem accusantium doloremque laudantium\",\n",
    "#            \"totam rem aperiam, eaque ipsa quae ab illo inventore\",\n",
    "#        ]\n",
    "#    },\n",
    "#    \"blicket_direct\": {\n",
    "#        \"prompts\": [\n",
    "#            \"You have two items. At least one is a blicket. If an item touches a machine and it turns on, the item is a blicket. You take one of the items and place it on a machine. The machine does not turn on. Is the item a blicket?\",\n",
    "#            \"You have two items. At least one is a blicket. If an item touches a machine and it turns on, the item is a blicket. You take one of the items and place it on a machine. The machine turns on. Is the item a blicket?\",\n",
    "#            \"You have two tools. At least one of the tools is magic. If a tool is magic, it can fix anything. If a tool is not magic, it cannot fix anything. You take one of the tools and try to fix a washing machine. You fail to fix it. Is the tool you used magic?\",\n",
    "#            \"You have two tools. At least one of the tools is magic. If a tool is magic, it can fix anything. If a tool is not magic, it cannot fix anything. You take one of the tools and try to fix a washing machine. You fix it! Is the tool you used magic?\",\n",
    "#            \"I see four eggs sitting on a table. The waiter told me that at least 3 of the eggs are hard boiled. If an egg is hard boiled, it will spin evenly. If it is not, it will spin wobbly. I see the waiter take one of the eggs and spin it. The egg spins wobbly. Is that egg hardboiled?\",\n",
    "#            \"I see four eggs sitting on a table. The waiter told me that at least 3 of the eggs are hard boiled. If an egg is hard boiled, it will spin evenly. If it is not, it will spin wobbly. I see the waiter take one of the eggs and spin it. The egg spins evenly. Is that egg hardboiled?\",\n",
    "#        ],\n",
    "#        \"answers\": [\n",
    "#            \"no, it is not\",\n",
    "#            \"yes, it is\",\n",
    "#            \"no, it is not\",\n",
    "#            \"yes, it is\",\n",
    "#            \"no, it is not\",\n",
    "#            \"yes, it is\",\n",
    "#        ]\n",
    "#    },\n",
    "#    \"blicket_implicit\": {\n",
    "#        \"prompts\": [\n",
    "#            \"You have two items. At least one is a blicket. If an item touches a machine and the machine turns on, the item is a blicket. You take one of the items and place it on a machine. The machine does not turn on. Is the other item a blicket?\",\n",
    "#            \"You have two items. At least one is a blicket. If an item touches a machine and the machine turns on, the item is a blicket. You take one of the items and place it on a machine. The machine turns on. Is the other item a blicket?\",\n",
    "#            \"You have two items. Only one is a blicket. If an item touches a machine and it turns on, the item is a blicket. You take one of the items and place it on a machine. The machine turns on. Is the other item a blicket?\",\n",
    "#            \n",
    "#            \"You have two tools. At least one of the tools is magic. If a tool is magic, it can fix anything. If a tool is not magic, it cannot fix anything. You take one of the tools and try to fix a washing machine. You fail to fix it. Is the tool you did not use magic?\",\n",
    "#            \"You have two tools. At least one of the tools is magic. If a tool is magic, it can fix anything. If a tool is not magic, it cannot fix anything. You take one of the tools and try to fix a washing machine. You fix it! Is the tool that you did not use magic?\",\n",
    "#            \"You have two tools. Only one of the tools is magic. If a tool is magic, it can fix anything. If a tool is not magic, it cannot fix anything. You take one of the tools and try to fix a washing machine. You fix it! Is the tool that you did not use magic?\",\n",
    "#            \n",
    "#            \"I see four eggs sitting on a table. The waiter told me that at least 3 of the eggs are hard boiled. If an egg is hard boiled, it will spin evenly. If it is not, it will spin wobbly. I see the waiter take one of the eggs and spin it. The egg spins wobbly. Are the other eggs all hardboiled?\",\n",
    "#            \"I see four eggs sitting on a table. The waiter told me that at least 3 of the eggs are hard boiled. If an egg is hard boiled, it will spin evenly. If it is not, it will spin wobbly. I see the waiter take one of the eggs and spin it. The egg spins evenly. Are the other eggs all hardboiled?\",\n",
    "#            \"I see four eggs sitting on a table. The waiter told me that at only 3 of the eggs are hard boiled. If an egg is hard boiled, it will spin evenly. If it is not, it will spin wobbly. I see the waiter take one of the eggs and spin it. The egg spins evenly. Are the other eggs all hardboiled?\",\n",
    "#        ],\n",
    "#        \"answers\": [\n",
    "#            \"yes, it is\",\n",
    "#            \"we cannot know the answer from the given information\",\n",
    "#            \"no, it is not\",\n",
    "#            \n",
    "#            \"yes, it is\",\n",
    "#            \"we cannot know the answer from the given information\",\n",
    "#            \"no, it is not\",\n",
    "#            \n",
    "#            \"yes, they are\",\n",
    "#            \"we cannot know the answer from the given information\",\n",
    "#            \"no, they are not\",\n",
    "#        ]\n",
    "#    }\n",
    "#}\n",
    "#\n",
    "#string = small_dataset[\"rand\"][\"prompts\"][0]\n",
    "#string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3e3dd6-73c3-47eb-b76e-0190f413a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
    "#\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931728e2-f3d0-47f2-8496-9634d6b02ccb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8439d3b5-8b17-4d5b-9816-0eae65960a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 100\n",
    "bsize = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22a4098d-f972-4421-8217-97a99104e594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset glue (/home/grantsrb/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"glue\", \"mrpc\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2146e353-879f-4ed0-8a04-0d0288b22f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='hf-internal-testing/tiny-random-gptj', vocab_size=1000, model_max_len=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab4aa8e-4d48-45e6-bbc3-d591130f9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokens = {\n",
    "    \"pad_token\": \"[PAD]\",\n",
    "    \"cls_token\": \"[CLS]\", # Using CLS token as compression token\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4da86b81-3142-487a-8f66-7799224e3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_added = tokenizer.add_special_tokens(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "764dcf59-d118-4d8f-add8-914f6b06ad8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,h = hface_model.transformer.wte.weight.shape\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9376f41-9248-433c-bc0a-ddacdbc9ec9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(1002, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hface_model.resize_token_embeddings(n+num_added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1a5c044-0bfa-49b0-8874-f61fa248c6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'heyo bo[CLS]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"heyo bo\"\n",
    "x = s[:100] + \"[CLS]\"\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d572ece-a2f9-4e3b-aa6f-f01b0e1c1af4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082aa61873b6444082e850c20fa991e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def encode(examples):\n",
    "    sent1 = [s + tokenizer.cls_token for s in examples[\"sentence1\"]]\n",
    "    inpts = tokenizer(sent1,padding=\"max_length\", max_length=MAX_SEQ_LEN, truncation=True, return_tensors=\"pt\")\n",
    "    sent2 = [s + tokenizer.eos_token for s in examples[\"sentence2\"]]\n",
    "    outs = tokenizer(sent2,padding=\"max_length\", max_length=MAX_SEQ_LEN, truncation=True , return_tensors=\"pt\")\n",
    "    \n",
    "    examples[\"label\"] = torch.LongTensor(examples[\"label\"])\n",
    "    idx = examples[\"label\"]==0\n",
    "    \n",
    "    outs[\"input_ids\"][idx] = inpts[\"input_ids\"][idx].clone()\n",
    "    outs[\"attention_mask\"][idx] = inpts[\"attention_mask\"][idx].clone()\n",
    "    outs[\"input_ids\"][outs[\"input_ids\"]==tokenizer.cls_token_id] = tokenizer.eos_token_id\n",
    "    \n",
    "    idx = (inpts[\"input_ids\"]==tokenizer.cls_token_id).float().reshape(len(idx),-1).sum(-1)\n",
    "    if idx.sum() != len(idx):\n",
    "        i = torch.argmax((idx==0).float())\n",
    "        inpts[\"input_ids\"][i,-1] = tokenizer.cls_token_id\n",
    "    idx = (outs[\"input_ids\"]==tokenizer.eos_token_id).float().reshape(len(examples[\"label\"]),-1).sum(-1)\n",
    "    if idx.sum() != len(examples[\"label\"]):\n",
    "        i = torch.argmax((idx==0).float())\n",
    "        outs[\"input_ids\"][i,-1] = tokenizer.eos_token_id\n",
    "    \n",
    "    #s = (inpts[\"input_ids\"]==tokenizer.cls_token_id).float().reshape(len(idx),-1).sum()\n",
    "    #if s != len(inpts[\"input_ids\"]):\n",
    "    #    print(\"CLS token id:\", tokenizer.cls_token_id)\n",
    "    #    print(\"Sum:\", s)\n",
    "    #    print(\"Len:\", len(inpts[\"input_ids\"]))\n",
    "    #    x = inpts[\"input_ids\"]\n",
    "    #    idx = (x==tokenizer.cls_token_id).float().reshape(x.shape[0],-1).sum(-1)\n",
    "    #    idx = torch.argmax((idx==0).float())\n",
    "    #    print(\"idx:\", idx)\n",
    "    #    print(sent1[idx])\n",
    "    #    print(inpts[\"input_ids\"][idx])\n",
    "    #    print()\n",
    "    #    print()\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\":        inpts[\"input_ids\"],\n",
    "        \"attention_mask\":   inpts[\"attention_mask\"],\n",
    "        \"output_ids\":       outs[\"input_ids\"],\n",
    "        \"output_attn_mask\": outs[\"attention_mask\"],\n",
    "        \"labels\":           examples[\"label\"],\n",
    "    }\n",
    "    \n",
    "dataset = dataset.map(encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e34b702-5c35-420b-9100-44ee533460c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask', 'output_ids', 'output_attn_mask', 'labels'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d48426f-b51e-4413-904d-58a670d43a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf5b4cbf-a41d-4877-8639-7e6580960888",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[\"output_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea7816f6-8d0f-49dd-af78-8a8821ae3f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'output_ids', 'output_attn_mask', 'labels'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns([\"sentence1\", \"sentence2\", \"idx\", \"label\"])\n",
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f2d5d9a-2444-461b-bcdb-e7cb24ee310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(type=\"torch\")\n",
    "#dataset.set_format(type=\"torch\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=bsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e6ea042-9f30-4528-a4af-aa557f27bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  41,   78,  212,  418,   84,  224,  422,  320,  214,  243,  204,  236,\n",
      "          85,  216,   68,  288,  201,  763,   69,  281,   75,  204,  274,  326,\n",
      "         221,   74,  302,  557,  872,  437,   73,  257,  249,  268,   83,  487,\n",
      "          69,  218,  198,  254,  386,  201,  203,  288,  223,  331,  398,  254,\n",
      "         617,  267,  272,  213,  342,  660,  242,  274,  322,  227,  293,  788,\n",
      "         209, 1001, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "        1000, 1000, 1000, 1000])\n",
      "tensor([  41,   78,  212,  418,   84,  224,  422,  320,  214,  243,  204,  236,\n",
      "          85,  216,   68,  288,  201,  763,   69,  281,   75,  204,  274,  326,\n",
      "         221,   74,  302,  557,  872,  437,   73,  257,  249,  268,   83,  487,\n",
      "          69,  218,  198,  254,  386,  201,  203,  288,  223,  331,  398,  254,\n",
      "         617,  267,  272,  213,  342,  660,  242,  274,  322,  227,  293,  788,\n",
      "         209,    0, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "        1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
      "        1000, 1000, 1000, 1000])\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(dataloader))\n",
    "idx = data[\"labels\"]==0\n",
    "print(data[\"input_ids\"][idx][0])\n",
    "print(data[\"output_ids\"][idx][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a8a0c0-6a1e-42f1-972a-0c9666f2bb9b",
   "metadata": {},
   "source": [
    "## Data Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d27c250-9e08-407c-8245-4c83041751bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(dataloader))\n",
    "with torch.no_grad():\n",
    "    inpts = {\n",
    "        \"input_ids\": data[\"input_ids\"],\n",
    "        \"attention_mask\": data[\"attention_mask\"],\n",
    "    }\n",
    "    outputs = hface_model.transformer(**inpts)\n",
    "    #logits = outputs.logits\n",
    "    #print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef602f2d-de5c-42d5-8c7b-8973a91c5291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'past_key_values'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a0b1516-2ddf-4c1f-80ba-bf9f4bca60fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 100, 32])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"last_hidden_state\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d02cffb0-4add-4d08-a792-c654936cef04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs[\"past_key_values\"]) # Number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a065f25-fa43-47ff-8a81-a596b1a8bcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4, 100, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"past_key_values\"][0][0].shape # Keys of first layer (or values, I'm not sure which, but probably keys because of naming key_values order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b858f69-3bec-46f8-ad93-6633a625dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.transformer(inputs_embeds=outputs[\"last_hidden_state\"], attention_mask=inpts[\"attention_mask\"]) # Use this to argue embeddings instead of ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92c13ca2-32df-4d4e-be45-117fc3e20a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"labels\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae91e0c-29c6-4c3e-91ef-0e42ffff2e39",
   "metadata": {},
   "source": [
    "Positive Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a41a259-9652-44ea-aa27-00b3d459f6cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With the economy sluggish, producers have had a tough time trying to raise prices. [CLS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(data[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09f7e54b-0b94-4428-bdcc-4267924bbe64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With the economy sluggish, producers have had a tough time trying to raise prices.<|endoftext|> [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(data[\"output_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8f1c2-125e-40e5-a28e-268a3d9dfdc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "533641e8-2780-4a4c-92a1-2220faf95bcc",
   "metadata": {},
   "source": [
    "\n",
    "Negative Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fffdd09e-33db-4f18-a003-ce80d68968d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gore said while the Patriot Act made some needed changes, it has \" turned out to be, on balance, a terrible mistake. \" [CLS] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(data[\"input_ids\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b5fad74-7838-4034-b246-3fc370e7d81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gore said while the Patriot Act made some needed changes, it has \" turned out to be, on balance, a terrible mistake. \"<|endoftext|> [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(data[\"output_ids\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4432791c-40a4-482a-941c-0f7f41895c0a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fabc6aa6-abfd-4697-bd47-63b12585ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceAutoEncoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Trains a new token type to compress a sentence into a single vector representation\n",
    "    \"\"\"\n",
    "    def __init__(self, model, tokenizer, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        model: hugging face transformer model\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hface_model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.CLS_ID = tokenizer.cls_token_id\n",
    "        self.CLS = tokenizer.cls_token\n",
    "        self.EOS_ID = tokenizer.eos_token_id\n",
    "        self.EOS = tokenizer.eos_token\n",
    "        \n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        data: dict\n",
    "            \"input_ids\": LongTensor (B,S1)\n",
    "                the token indices of the input sequence. The CLS token should be appended to the end of each sentence.\n",
    "            \"attention_mask\": LongTensor (B,S1)\n",
    "                attention mask for padding purposes. 0s mean padding.\n",
    "            \"output_ids\": LongTensor (B,S2)\n",
    "                the token indices of the target sequence. An EOS token should be appended to the end of each sentence\n",
    "            \"output_attn_mask\": LongTensor (B,S2)\n",
    "                attention mask for padding purposes. 0s mean padding.\n",
    "        \"\"\"\n",
    "        \n",
    "        model = self.hface_model\n",
    "        inpt_embs = model.transformer.wte(data[\"input_ids\"]).data\n",
    "        idx = data[\"input_ids\"]==self.CLS_ID\n",
    "        inpt_embs[idx] = 0\n",
    "        inpt_embs[idx] += model.transformer.wte.weight[self.CLS_ID]\n",
    "        out_embs =  model.transformer.wte(data[\"output_ids\"]).data\n",
    "        \n",
    "        \n",
    "        fx = model.transformer(inputs_embeds=inpt_embs, attention_mask=data[\"attention_mask\"])\n",
    "        fx = fx[\"last_hidden_state\"][idx][:,None]\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            out_embs = torch.cat([fx,out_embs], dim=1)\n",
    "            attn = torch.cat([torch.ones_like(data[\"output_attn_mask\"][:,:1]), data[\"output_attn_mask\"]], dim=1)\n",
    "        except:\n",
    "            print(\"Data\")\n",
    "            for k in data: print(k, data[k].shape)\n",
    "            print(\"idx sum:\", idx.float().sum())\n",
    "            print(\"In Embds\", inpt_embs.shape)\n",
    "            print(\"Out Embds\", out_embs.shape)\n",
    "            print(\"FX\", fx.shape)\n",
    "            assert False\n",
    "        \n",
    "        preds = model(inputs_embeds=out_embs, attention_mask=attn).logits\n",
    "        return preds\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88a1c8d9-fb75-4543-8f65-9319b9424808",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceAutoEncoder(hface_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432c9959-6a37-421c-ad6e-cc51248c58e6",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17624719-7c0e-4909-8675-0f50d0a96c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "l2 = 1e-3\n",
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "483530ff-8e15-4f87-ae88-bbd14d95b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.hface_model.transformer.wte.parameters(), lr=lr, weight_decay=l2)\n",
    "loss_fxn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26ec7221-89f4-458c-975b-f718d5e1c8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning Epoch 0\n",
      "Loss 6.91259 -- Acc: 0.0\n",
      "Loss 6.91193 -- Acc: 0.0\n",
      "Loss 6.92265 -- Acc: 0.0\n",
      "Loss 6.92159 -- Acc: 0.0\n",
      "Loss 6.92124 -- Acc: 0.0\n",
      "Loss 6.91839 -- Acc: 0.0\n",
      "Loss 6.92472 -- Acc: 0.0\n",
      "Loss 6.92621 -- Acc: 0.0\n",
      "Loss 6.92465 -- Acc: 0.0\n",
      "Loss 6.91898 -- Acc: 0.0\n",
      "Loss 6.91775 -- Acc: 0.0\n",
      "Loss 6.92092 -- Acc: 0.0\n",
      "Loss 6.91833 -- Acc: 0.0\n",
      "Loss 6.92593 -- Acc: 0.0\n",
      "Loss 6.91921 -- Acc: 0.0\n",
      "Loss 6.92712 -- Acc: 0.0\n",
      "Loss 6.92914 -- Acc: 0.0\n",
      "Loss 6.91767 -- Acc: 0.0\n",
      "Loss 6.9271 -- Acc: 0.0\n",
      "Loss 6.91894 -- Acc: 0.0\n",
      "Loss 6.92484 -- Acc: 0.0\n",
      "Loss 6.92443 -- Acc: 0.0\n",
      "Loss 6.91963 -- Acc: 0.0\n",
      "Avg Loss: 1591.58429 -- Avg Acc: 0.0\n",
      "\n",
      "\n",
      "Beginning Epoch 1\n",
      "Loss 6.92404 -- Acc: 0.0\n",
      "Loss 6.92239 -- Acc: 0.0\n",
      "Loss 6.91871 -- Acc: 0.0\n",
      "Loss 6.91928 -- Acc: 0.0\n",
      "Loss 6.92657 -- Acc: 0.0\n",
      "Loss 6.91783 -- Acc: 0.0\n",
      "Loss 6.92411 -- Acc: 0.0\n",
      "Loss 6.91212 -- Acc: 0.0\n",
      "Loss 6.91373 -- Acc: 0.0\n",
      "Loss 6.91901 -- Acc: 0.0\n",
      "Loss 6.91034 -- Acc: 0.0\n",
      "Loss 6.91262 -- Acc: 0.0\n",
      "Loss 6.91773 -- Acc: 0.0\n",
      "Loss 6.91504 -- Acc: 0.0\n",
      "Loss 6.92567 -- Acc: 0.0\n",
      "Loss 6.9262 -- Acc: 0.0\n",
      "Loss 6.9195 -- Acc: 0.0\n",
      "Loss 6.91699 -- Acc: 0.0\n",
      "Loss 6.91896 -- Acc: 0.0\n",
      "Loss 6.9224 -- Acc: 0.0\n",
      "Loss 6.91952 -- Acc: 0.0\n",
      "Loss 6.9214 -- Acc: 0.0\n",
      "Loss 6.92311 -- Acc: 0.0\n",
      "Avg Loss: 1591.58964 -- Avg Acc: 0.0\n",
      "\n",
      "\n",
      "Beginning Epoch 2\n",
      "Loss 6.9116 -- Acc: 0.0\n",
      "Loss 6.92112 -- Acc: 0.0\n",
      "Loss 6.92533 -- Acc: 0.0\n",
      "Loss 6.92198 -- Acc: 0.0\n",
      "Loss 6.9263 -- Acc: 0.0\n",
      "Loss 6.91823 -- Acc: 0.0\n",
      "Loss 6.92733 -- Acc: 0.0\n",
      "Loss 6.92107 -- Acc: 0.0\n",
      "Loss 6.92372 -- Acc: 0.0\n",
      "Loss 6.92254 -- Acc: 0.0\n",
      "Loss 6.92114 -- Acc: 0.0\n",
      "Loss 6.9172 -- Acc: 0.0\n",
      "Loss 6.91639 -- Acc: 0.0\n",
      "Loss 6.91689 -- Acc: 0.0\n",
      "Loss 6.92102 -- Acc: 0.0\n",
      "Loss 6.91686 -- Acc: 0.0\n",
      "Loss 6.92769 -- Acc: 0.0\n",
      "Loss 6.91567 -- Acc: 0.0\n",
      "Loss 6.91871 -- Acc: 0.0\n",
      "Loss 6.91945 -- Acc: 0.0\n",
      "Loss 6.92175 -- Acc: 0.0\n",
      "Loss 6.91823 -- Acc: 0.0\n",
      "Loss 6.91913 -- Acc: 0.0\n",
      "Avg Loss: 1591.59042 -- Avg Acc: 0.0\n",
      "\n",
      "\n",
      "Beginning Epoch 3\n",
      "Loss 6.90822 -- Acc: 0.0\n",
      "Loss 6.91674 -- Acc: 0.0\n",
      "Loss 6.91714 -- Acc: 0.0\n",
      "Loss 6.9213 -- Acc: 0.0\n",
      "Loss 6.9197 -- Acc: 0.0\n",
      "Loss 6.9162 -- Acc: 0.0\n",
      "Loss 6.92443 -- Acc: 0.0\n",
      "Loss 6.92133 -- Acc: 0.0\n",
      "Loss 6.91689 -- Acc: 0.0\n",
      "Loss 6.92413 -- Acc: 0.0\n",
      "Loss 6.92587 -- Acc: 0.0\n",
      "Loss 6.92172 -- Acc: 0.0\n",
      "Loss 6.91532 -- Acc: 0.0\n",
      "Loss 6.9175 -- Acc: 0.0\n",
      "Loss 6.91562 -- Acc: 0.0\n",
      "Loss 6.92086 -- Acc: 0.0\n",
      "Loss 6.91911 -- Acc: 0.0\n",
      "Loss 6.92287 -- Acc: 0.0\n",
      "Loss 6.92424 -- Acc: 0.0\n",
      "Loss 6.92322 -- Acc: 0.0\n",
      "Loss 6.92028 -- Acc: 0.0\n",
      "Loss 6.92966 -- Acc: 0.0\n",
      "Loss 6.92466 -- Acc: 0.0\n",
      "Avg Loss: 1591.58029 -- Avg Acc: 0.0\n",
      "\n",
      "\n",
      "Beginning Epoch 4\n",
      "Loss 6.92596 -- Acc: 0.0\n",
      "Loss 6.9233 -- Acc: 0.0\n",
      "Loss 6.92531 -- Acc: 0.0\n",
      "Loss 6.91948 -- Acc: 0.0\n",
      "Loss 6.92307 -- Acc: 0.0\n",
      "Loss 6.91418 -- Acc: 0.0\n",
      "Loss 6.91347 -- Acc: 0.0\n",
      "Loss 6.92305 -- Acc: 0.0\n",
      "Loss 6.92714 -- Acc: 0.0\n",
      "Loss 6.9118 -- Acc: 0.0\n",
      "Loss 6.9156 -- Acc: 0.0\n",
      "Loss 6.91284 -- Acc: 0.0\n",
      "Loss 6.91424 -- Acc: 0.0\n",
      "Loss 6.92001 -- Acc: 0.0\n",
      "Loss 6.92344 -- Acc: 0.0\n",
      "Loss 6.91837 -- Acc: 0.0\n",
      "Loss 6.90992 -- Acc: 0.0\n",
      "Loss 6.92025 -- Acc: 0.0\n",
      "Loss 6.91876 -- Acc: 0.0\n",
      "Loss 6.91879 -- Acc: 0.0\n",
      "Loss 6.91961 -- Acc: 0.0\n",
      "Loss 6.91746 -- Acc: 0.0\n",
      "Loss 6.92512 -- Acc: 0.0\n",
      "Avg Loss: 1591.5701 -- Avg Acc: 0.0\n",
      "\n",
      "\n",
      "Beginning Epoch 5\n",
      "Loss 6.92039 -- Acc: 0.0\n",
      "Loss 6.91932 -- Acc: 0.0\n",
      "Loss 6.92177 -- Acc: 0.0\n",
      "Loss 6.92264 -- Acc: 0.0\n",
      "Loss 6.91466 -- Acc: 0.0\n",
      "Loss 6.91719 -- Acc: 0.0\n",
      "Loss 6.91682 -- Acc: 0.0\n",
      "Loss 6.922 -- Acc: 0.0\n",
      "Loss 6.91169 -- Acc: 0.0\n",
      "Loss 6.92146 -- Acc: 0.0\n",
      "Loss 6.92825 -- Acc: 0.0\n",
      "Loss 6.91218 -- Acc: 0.0\n",
      "Loss 6.91957 -- Acc: 0.0\n",
      "Loss 6.91155 -- Acc: 0.0\n",
      "Loss 6.91738 -- Acc: 0.0\n",
      "Loss 6.91962 -- Acc: 0.0\n",
      "Loss 6.92428 -- Acc: 0.0\n",
      "Loss 6.92099 -- Acc: 0.0\n",
      "Loss 6.92077 -- Acc: 0.0\n",
      "Loss 6.91609 -- Acc: 0.0\n",
      "Loss 6.91742 -- Acc: 0.0\n",
      "Loss 6.91739 -- Acc: 0.0\n",
      "Loss 6.91906 -- Acc: 0.0\n",
      "Avg Loss: 1591.56142 -- Avg Acc: 0.0\n",
      "\n",
      "\n",
      "Beginning Epoch 6\n",
      "Loss 6.92183 -- Acc: 0.0\n",
      "Loss 6.91773 -- Acc: 0.0\n",
      "Loss 6.91349 -- Acc: 0.0\n",
      "Loss 6.92276 -- Acc: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      9\u001b[0m     data \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 10\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     preds \u001b[38;5;241m=\u001b[39m preds[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, preds\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     12\u001b[0m     labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36mSentenceAutoEncoder.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     34\u001b[0m inpt_embs[idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mwte\u001b[38;5;241m.\u001b[39mweight[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCLS_ID]\n\u001b[1;32m     35\u001b[0m out_embs \u001b[38;5;241m=\u001b[39m  model\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mwte(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m---> 38\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minpt_embs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m fx \u001b[38;5;241m=\u001b[39m fx[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast_hidden_state\u001b[39m\u001b[38;5;124m\"\u001b[39m][idx][:,\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/src/transformers/src/transformers/models/gptj/modeling_gptj.py:676\u001b[0m, in \u001b[0;36mGPTJModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    668\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    669\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    670\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    673\u001b[0m         head_mask[i],\n\u001b[1;32m    674\u001b[0m     )\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 676\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    685\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/src/transformers/src/transformers/models/gptj/modeling_gptj.py:310\u001b[0m, in \u001b[0;36mGPTJBlock.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    308\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    309\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 310\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/src/transformers/src/transformers/models/gptj/modeling_gptj.py:233\u001b[0m, in \u001b[0;36mGPTJAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    230\u001b[0m q_rot \u001b[38;5;241m=\u001b[39m query[:, :, :, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_dim]\n\u001b[1;32m    231\u001b[0m q_pass \u001b[38;5;241m=\u001b[39m query[:, :, :, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_dim :]\n\u001b[0;32m--> 233\u001b[0m sincos \u001b[38;5;241m=\u001b[39m \u001b[43mfixed_pos_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk_rot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m k_rot \u001b[38;5;241m=\u001b[39m apply_rotary_pos_emb(k_rot, sincos, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[1;32m    235\u001b[0m q_rot \u001b[38;5;241m=\u001b[39m apply_rotary_pos_emb(q_rot, sincos, offset\u001b[38;5;241m=\u001b[39moffset)\n",
      "File \u001b[0;32m~/src/transformers/src/transformers/models/gptj/modeling_gptj.py:62\u001b[0m, in \u001b[0;36mfixed_pos_embedding\u001b[0;34m(x, seq_dim, seq_len)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seq_len \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     seq_len \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[seq_dim]\n\u001b[0;32m---> 62\u001b[0m inv_freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m sinusoid_inp \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi , j -> i j\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39marange(seq_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat), inv_freq)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msin(sinusoid_inp), torch\u001b[38;5;241m.\u001b[39mcos(sinusoid_inp)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:32\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:643\u001b[0m, in \u001b[0;36mTensor.__rdiv__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rdiv__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreciprocal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "for epoch in range(n_epochs):\n",
    "    print()\n",
    "    print(\"Beginning Epoch\", epoch)\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    for i,data in enumerate(dataloader):\n",
    "        data = {k: v.cuda() for k,v in data.items()}\n",
    "        preds = model(data)\n",
    "        preds = preds[:,:-1].reshape(-1, preds.shape[-1])\n",
    "        labels = data[\"output_ids\"].reshape(-1)\n",
    "        idx = labels!=tokenizer.pad_token_id\n",
    "        loss = loss_fxn(preds[idx], labels[idx])\n",
    "        avg_loss += loss.item()\n",
    "        argmax = torch.argmax(preds[idx])\n",
    "        acc = (argmax==labels[idx]).float().mean()\n",
    "        avg_acc += acc.item()\n",
    "        if i%10==0: print(\"Loss\", round(loss.item(), 5), \"-- Acc:\", round(acc.item(), 5))\n",
    "    print(\"Avg Loss:\", round(avg_loss, 5), \"-- Avg Acc:\", round(avg_acc, 5))\n",
    "    print()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb16e4-960e-4db7-a501-31edc66827cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
